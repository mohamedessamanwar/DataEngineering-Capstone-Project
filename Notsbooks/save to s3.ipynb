{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3193eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from io import StringIO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c93ad3",
   "metadata": {},
   "source": [
    "# immigrations_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "533568c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "immigrations_table = pd.read_csv(r'C:\\Users\\AL-FAJR\\Desktop\\spark_project\\fils\\immigrations_table.csv\\immigrations_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deeb412d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cic_id</th>\n",
       "      <th>port</th>\n",
       "      <th>arrive_state</th>\n",
       "      <th>arrive_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1195600</td>\n",
       "      <td>OGG</td>\n",
       "      <td>FL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1387607</td>\n",
       "      <td>BOS</td>\n",
       "      <td>MA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4299497</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NY</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2522724</td>\n",
       "      <td>NEW</td>\n",
       "      <td>NY</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>267021</td>\n",
       "      <td>BOS</td>\n",
       "      <td>MA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>1776348</td>\n",
       "      <td>DAL</td>\n",
       "      <td>TX</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>5660225</td>\n",
       "      <td>NEW</td>\n",
       "      <td>NY</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>3300843</td>\n",
       "      <td>NEW</td>\n",
       "      <td>NJ</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>813390</td>\n",
       "      <td>PHO</td>\n",
       "      <td>NC</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>1560415</td>\n",
       "      <td>CHI</td>\n",
       "      <td>IL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>904 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cic_id port arrive_state  arrive_month\n",
       "0    1195600  OGG           FL             4\n",
       "1    1387607  BOS           MA             4\n",
       "2    4299497  NYC           NY             4\n",
       "3    2522724  NEW           NY             4\n",
       "4     267021  BOS           MA             4\n",
       "..       ...  ...          ...           ...\n",
       "899  1776348  DAL           TX             4\n",
       "900  5660225  NEW           NY             4\n",
       "901  3300843  NEW           NJ             4\n",
       "902   813390  PHO           NC             4\n",
       "903  1560415  CHI           IL             4\n",
       "\n",
       "[904 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigrations_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fd5cace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"immigrations_table\" (\n",
      "\"index\" INTEGER,\n",
      "  \"cic_id\" INTEGER,\n",
      "  \"birth_year\" INTEGER,\n",
      "  \"age\" INTEGER,\n",
      "  \"gender\" TEXT,\n",
      "  \"airline\" TEXT,\n",
      "  \"flight_num\" TEXT,\n",
      "  \"visa_type\" TEXT,\n",
      "  \"visa_class\" TEXT,\n",
      "  \"visa_issue_state\" TEXT,\n",
      "  \"mode\" TEXT,\n",
      "  \"citizen_country_name\" TEXT,\n",
      "  \"resident_country_name\" TEXT\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Reset the index if needed (optional)\n",
    "immigrations_table.reset_index(inplace=True)\n",
    "\n",
    "# Generate the SQL schema\n",
    "schema = pd.io.sql.get_schema(immigrations_table, 'immigrations_table')\n",
    "\n",
    "# Print the generated SQL schema\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b656b8e",
   "metadata": {},
   "source": [
    "# immigrants_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95fba19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "immigrants_table = pd.read_csv(r'C:\\Users\\AL-FAJR\\Desktop\\spark_project\\fils\\immigrants_table.csv\\immigrants_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d927280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"immigrants_table\" (\n",
      "\"index\" INTEGER,\n",
      "  \"cic_id\" INTEGER,\n",
      "  \"birth_year\" INTEGER,\n",
      "  \"age\" INTEGER,\n",
      "  \"gender\" TEXT,\n",
      "  \"airline\" TEXT,\n",
      "  \"flight_num\" TEXT,\n",
      "  \"visa_type\" TEXT,\n",
      "  \"visa_class\" TEXT,\n",
      "  \"visa_issue_state\" TEXT,\n",
      "  \"mode\" TEXT,\n",
      "  \"citizen_country_name\" TEXT,\n",
      "  \"resident_country_name\" TEXT\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Reset the index if needed (optional)\n",
    "immigrants_table.reset_index(inplace=True)\n",
    "\n",
    "# Generate the SQL schema\n",
    "schema = pd.io.sql.get_schema(immigrants_table, 'immigrants_table')\n",
    "\n",
    "# Print the generated SQL schema\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e8522a",
   "metadata": {},
   "source": [
    "# demographics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be9aad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "demographics_table = pd.read_csv(r'C:\\Users\\AL-FAJR\\Desktop\\spark_project\\fils\\demographics_table.csv\\demographics_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e58e991c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"demographics_table\" (\n",
      "\"index\" INTEGER,\n",
      "  \"state_code\" TEXT,\n",
      "  \"state\" TEXT,\n",
      "  \"median_age\" INTEGER,\n",
      "  \"male_population\" INTEGER,\n",
      "  \"female_population\" INTEGER,\n",
      "  \"total_population\" INTEGER,\n",
      "  \"veterans_num\" REAL,\n",
      "  \"foreign_born_population\" REAL,\n",
      "  \"avg_household_size\" REAL,\n",
      "  \"american_indian_alaska_native\" INTEGER,\n",
      "  \"asian\" INTEGER,\n",
      "  \"african_american\" INTEGER,\n",
      "  \"hispanic_latino\" INTEGER,\n",
      "  \"white\" INTEGER\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Reset the index if needed (optional)\n",
    "demographics_table.reset_index(inplace=True)\n",
    "\n",
    "# Generate the SQL schema\n",
    "schema = pd.io.sql.get_schema(demographics_table, 'demographics_table')\n",
    "\n",
    "# Print the generated SQL schema\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325e1f78",
   "metadata": {},
   "source": [
    "# airports_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf9c93b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "airports_table = pd.read_csv(r'C:\\Users\\AL-FAJR\\Desktop\\spark_project\\fils\\airports_table.csv\\airports_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76949d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"airports_table\" (\n",
      "\"level_0\" INTEGER,\n",
      "  \"index\" INTEGER,\n",
      "  \"iata_code\" TEXT,\n",
      "  \"name\" TEXT,\n",
      "  \"type\" TEXT,\n",
      "  \"state\" TEXT,\n",
      "  \"elevation_ft\" INTEGER,\n",
      "  \"latitude\" REAL,\n",
      "  \"longitude\" REAL\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Reset the index if needed (optional)\n",
    "airports_table.reset_index(inplace=True)\n",
    "\n",
    "# Generate the SQL schema\n",
    "schema = pd.io.sql.get_schema(airports_table, 'airports_table')\n",
    "\n",
    "# Print the generated SQL schema\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde4c601",
   "metadata": {},
   "source": [
    "# Load to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dbefd8",
   "metadata": {},
   "source": [
    "# In the specific code example you provided, the access key ID and secret access key are used to authenticate your script when uploading a CSV file to an S3 bucket. The access key credentials should have the necessary permissions (defined in their associated IAM policies) to read from the immigrations_table DataFrame and write data to the specified S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfb89b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'KRN17N3B4B9E8SM9',\n",
       "  'HostId': 'SVYZqHLbaA2Uv+/aMqoxqNsVafp+M1JSk0HLZxqYYme5ouyyUnaquafLz0s43FydC5c+bvga39M=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'SVYZqHLbaA2Uv+/aMqoxqNsVafp+M1JSk0HLZxqYYme5ouyyUnaquafLz0s43FydC5c+bvga39M=',\n",
       "   'x-amz-request-id': 'KRN17N3B4B9E8SM9',\n",
       "   'date': 'Tue, 26 Sep 2023 05:21:42 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"54d208644ff58c72215db51764ca1c50\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 1},\n",
       " 'ETag': '\"54d208644ff58c72215db51764ca1c50\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from io import StringIO\n",
    "\n",
    "# Define your S3 bucket and CSV data\n",
    "bucket = 'spark-project-1'  # Replace with your S3 bucket name\n",
    "\n",
    "# AWS credentials setup\n",
    "aws_access_key_id = ''\n",
    "aws_secret_access_key = ''\n",
    "# Create an S3 resource and upload the CSV data\n",
    "s3_resource = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key\n",
    "  \n",
    ")\n",
    "\n",
    "\n",
    "# Use StringIO to create an in-memory text stream for the CSV data\n",
    "csv_buffer = StringIO()\n",
    "immigrations_table.to_csv(csv_buffer, index=False) \n",
    "\n",
    "s3_resource.Object(bucket, 'output/immigrations_table.csv').put(Body=csv_buffer.getvalue())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1508b4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'Y8ZS2QQJYSAN065W',\n",
       "  'HostId': '3DXCqqyzMLNj5cwG3tA9vO1OHYNJZdu2LsO/4xCQL15KkN1t4T8vpjrL6W70SGR6PXRwkigQYwE=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '3DXCqqyzMLNj5cwG3tA9vO1OHYNJZdu2LsO/4xCQL15KkN1t4T8vpjrL6W70SGR6PXRwkigQYwE=',\n",
       "   'x-amz-request-id': 'Y8ZS2QQJYSAN065W',\n",
       "   'date': 'Tue, 26 Sep 2023 05:20:08 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"d2713c9f2547ae45a1d00c32c8e023d9\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 1},\n",
       " 'ETag': '\"d2713c9f2547ae45a1d00c32c8e023d9\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from io import StringIO\n",
    "\n",
    "# Define your S3 bucket and CSV data\n",
    "bucket = 'spark-project-1'  # Replace with your S3 bucket name\n",
    "\n",
    "# AWS credentials setup\n",
    "aws_access_key_id = ''\n",
    "aws_secret_access_key = ''\n",
    "# Create an S3 resource and upload the CSV data\n",
    "s3_resource = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key\n",
    "  \n",
    ")\n",
    "# Use StringIO to create an in-memory text stream for the CSV data\n",
    "csv_buffer = StringIO()\n",
    "immigrants_table.to_csv(csv_buffer, index=False) \n",
    "\n",
    "s3_resource.Object(bucket, 'output/immigrants_table.csv').put(Body=csv_buffer.getvalue())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ce2cce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '80QG81KMP6KSCK1N',\n",
       "  'HostId': 'CTvXWYvWWAgkn2lFTNSLiBMB4iFqWAPVvDT1dUJbQm7oQMSdiWE4+Qsncm8MupNVnNMIrg9LTM7VTLKqNW4XHA==',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'CTvXWYvWWAgkn2lFTNSLiBMB4iFqWAPVvDT1dUJbQm7oQMSdiWE4+Qsncm8MupNVnNMIrg9LTM7VTLKqNW4XHA==',\n",
       "   'x-amz-request-id': '80QG81KMP6KSCK1N',\n",
       "   'date': 'Tue, 26 Sep 2023 05:24:35 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"734c5d6ba79b2f973a51a589a4847c8f\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 1},\n",
       " 'ETag': '\"734c5d6ba79b2f973a51a589a4847c8f\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from io import StringIO\n",
    "\n",
    "# Define your S3 bucket and CSV data\n",
    "bucket = 'spark-project-1'  # Replace with your S3 bucket name\n",
    "\n",
    "# AWS credentials setup\n",
    "aws_access_key_id = ''\n",
    "aws_secret_access_key = ''\n",
    "# Create an S3 resource and upload the CSV data\n",
    "s3_resource = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key\n",
    "  \n",
    ")\n",
    "# Use StringIO to create an in-memory text stream for the CSV data\n",
    "csv_buffer = StringIO()\n",
    "demographics_table.to_csv(csv_buffer, index=False) \n",
    "\n",
    "s3_resource.Object(bucket, 'output/demographics_table.csv').put(Body=csv_buffer.getvalue())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e0be1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '0CXBARCKNNB1ANC5',\n",
       "  'HostId': 'AvKcK1nvnr5m5H300h9LFsF3cxkwpenuyIouDlJRkMCxmKO8nvtzrsMLxjvoYLyTYcOvvmKjNvgjawK7SyB+8g==',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'AvKcK1nvnr5m5H300h9LFsF3cxkwpenuyIouDlJRkMCxmKO8nvtzrsMLxjvoYLyTYcOvvmKjNvgjawK7SyB+8g==',\n",
       "   'x-amz-request-id': '0CXBARCKNNB1ANC5',\n",
       "   'date': 'Tue, 26 Sep 2023 05:27:26 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"fa15bb7b0aabc2ca065c6f138b629628\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 1},\n",
       " 'ETag': '\"fa15bb7b0aabc2ca065c6f138b629628\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from io import StringIO\n",
    "\n",
    "# Define your S3 bucket and CSV data\n",
    "bucket = 'spark-project-1'  # Replace with your S3 bucket name\n",
    "\n",
    "# AWS credentials setup\n",
    "aws_access_key_id = ''\n",
    "aws_secret_access_key = \n",
    "# Create an S3 resource and upload the CSV data\n",
    "s3_resource = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key\n",
    "  \n",
    ")\n",
    "# Use StringIO to create an in-memory text stream for the CSV data\n",
    "csv_buffer = StringIO()\n",
    "airports_table.to_csv(csv_buffer, index=False) \n",
    "\n",
    "s3_resource.Object(bucket, 'output/airports_table.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55704ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e607e61f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d6f18f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e6bd69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab45d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece68e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765a15b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2820e6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21790b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a6e1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c3378f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
